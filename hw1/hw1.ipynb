{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dependency Installation and Repository Cloning"
   ],
   "metadata": {
    "id": "kOyTYZgsq035"
   },
   "id": "kOyTYZgsq035"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run it if you're using this notebook in Google Colab"
   ],
   "metadata": {
    "id": "bIgHW9Muv5Ad"
   },
   "id": "bIgHW9Muv5Ad"
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone 'https://github.com/dakopecky/nlp-course-itmo.git'\n",
    "\n",
    "%cd nlp-course-itmo\n",
    "!git checkout hw1\n",
    "%cd hw1\n",
    "\n",
    "!pip install poetry\n",
    "!poetry config virtualenvs.create false\n",
    "!poetry install --no-ansi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2pvOkxAtnM4",
    "outputId": "4d7a01b6-80e4-4494-9623-84bf453048b4"
   },
   "id": "n2pvOkxAtnM4",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'nlp-course-itmo'...\n",
      "remote: Enumerating objects: 16, done.\u001B[K\n",
      "remote: Counting objects: 100% (16/16), done.\u001B[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001B[K\n",
      "remote: Total 16 (delta 3), reused 12 (delta 1), pack-reused 0\u001B[K\n",
      "Receiving objects: 100% (16/16), 75.93 KiB | 1.52 MiB/s, done.\n",
      "Resolving deltas: 100% (3/3), done.\n",
      "/content/nlp-course-itmo\n",
      "Branch 'hw1' set up to track remote branch 'hw1' from 'origin'.\n",
      "Switched to a new branch 'hw1'\n",
      "Collecting poetry\n",
      "  Downloading poetry-1.6.1-py3-none-any.whl (232 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m232.8/232.8 kB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting build<0.11.0,>=0.10.0 (from poetry)\n",
      "  Downloading build-0.10.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cachecontrol[filecache]<0.14.0,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.13.1)\n",
      "Collecting cleo<3.0.0,>=2.0.0 (from poetry)\n",
      "  Downloading cleo-2.0.1-py3-none-any.whl (77 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m77.3/77.3 kB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting crashtest<0.5.0,>=0.4.1 (from poetry)\n",
      "  Downloading crashtest-0.4.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting dulwich<0.22.0,>=0.21.2 (from poetry)\n",
      "  Downloading dulwich-0.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (512 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m512.2/512.2 kB\u001B[0m \u001B[31m24.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting installer<0.8.0,>=0.7.0 (from poetry)\n",
      "  Downloading installer-0.7.0-py3-none-any.whl (453 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m453.8/453.8 kB\u001B[0m \u001B[31m41.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting jsonschema<4.18.0,>=4.10.0 (from poetry)\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m90.4/90.4 kB\u001B[0m \u001B[31m12.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting keyring<25.0.0,>=24.0.0 (from poetry)\n",
      "  Downloading keyring-24.2.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.10/dist-packages (from poetry) (23.1)\n",
      "Requirement already satisfied: pexpect<5.0.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (4.8.0)\n",
      "Collecting pkginfo<2.0.0,>=1.9.4 (from poetry)\n",
      "  Downloading pkginfo-1.9.6-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (3.10.0)\n",
      "Collecting poetry-core==1.7.0 (from poetry)\n",
      "  Downloading poetry_core-1.7.0-py3-none-any.whl (426 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m426.4/426.4 kB\u001B[0m \u001B[31m39.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting poetry-plugin-export<2.0.0,>=1.5.0 (from poetry)\n",
      "  Downloading poetry_plugin_export-1.5.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pyproject-hooks<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.26 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.31.0)\n",
      "Collecting requests-toolbelt<2,>=0.9.1 (from poetry)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m54.5/54.5 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting shellingham<2.0,>=1.5 (from poetry)\n",
      "  Downloading shellingham-1.5.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.0.1)\n",
      "Collecting tomlkit<1.0.0,>=0.11.4 (from poetry)\n",
      "  Downloading tomlkit-0.12.1-py3-none-any.whl (37 kB)\n",
      "Collecting trove-classifiers>=2022.5.19 (from poetry)\n",
      "  Downloading trove_classifiers-2023.9.19-py3-none-any.whl (13 kB)\n",
      "Collecting virtualenv<21.0.0,>=20.22.0 (from poetry)\n",
      "  Downloading virtualenv-20.24.5-py3-none-any.whl (3.7 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.7/3.7 MB\u001B[0m \u001B[31m67.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from cachecontrol[filecache]<0.14.0,>=0.13.0->poetry) (1.0.5)\n",
      "Requirement already satisfied: filelock>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from cachecontrol[filecache]<0.14.0,>=0.13.0->poetry) (3.12.2)\n",
      "Collecting rapidfuzz<3.0.0,>=2.2.0 (from cleo<3.0.0,>=2.0.0->poetry)\n",
      "  Downloading rapidfuzz-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m34.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from dulwich<0.22.0,>=0.21.2->poetry) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18.0,>=4.10.0->poetry) (23.1.0)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.18.0,>=4.10.0->poetry)\n",
      "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.5/57.5 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting jaraco.classes (from keyring<25.0.0,>=24.0.0->poetry)\n",
      "  Downloading jaraco.classes-3.3.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.11.4 in /usr/local/lib/python3.10/dist-packages (from keyring<25.0.0,>=24.0.0->poetry) (6.8.0)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /usr/lib/python3/dist-packages (from keyring<25.0.0,>=24.0.0->poetry) (3.3.1)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /usr/lib/python3/dist-packages (from keyring<25.0.0,>=24.0.0->poetry) (0.7.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect<5.0.0,>=4.7.0->poetry) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.26->poetry) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.26->poetry) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.26->poetry) (2023.7.22)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv<21.0.0,>=20.22.0->poetry)\n",
      "  Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m468.9/468.9 kB\u001B[0m \u001B[31m35.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.0.0->poetry) (3.16.2)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from jaraco.classes->keyring<25.0.0,>=24.0.0->poetry) (10.1.0)\n",
      "Installing collected packages: trove-classifiers, distlib, virtualenv, tomlkit, shellingham, rapidfuzz, pyrsistent, poetry-core, pkginfo, jaraco.classes, installer, dulwich, crashtest, requests-toolbelt, keyring, jsonschema, cleo, build, poetry-plugin-export, poetry\n",
      "  Attempting uninstall: keyring\n",
      "    Found existing installation: keyring 23.5.0\n",
      "    Uninstalling keyring-23.5.0:\n",
      "      Successfully uninstalled keyring-23.5.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.19.0\n",
      "    Uninstalling jsonschema-4.19.0:\n",
      "      Successfully uninstalled jsonschema-4.19.0\n",
      "  Attempting uninstall: build\n",
      "    Found existing installation: build 1.0.3\n",
      "    Uninstalling build-1.0.3:\n",
      "      Successfully uninstalled build-1.0.3\n",
      "Successfully installed build-0.10.0 cleo-2.0.1 crashtest-0.4.1 distlib-0.3.7 dulwich-0.21.6 installer-0.7.0 jaraco.classes-3.3.0 jsonschema-4.17.3 keyring-24.2.0 pkginfo-1.9.6 poetry-1.6.1 poetry-core-1.7.0 poetry-plugin-export-1.5.0 pyrsistent-0.19.3 rapidfuzz-2.15.1 requests-toolbelt-1.0.0 shellingham-1.5.3 tomlkit-0.12.1 trove-classifiers-2023.9.19 virtualenv-20.24.5\n",
      "Skipping virtualenv creation, as specified in config file.\n",
      "Installing dependencies from lock file\n",
      "\n",
      "Package operations: 31 installs, 26 updates, 0 removals\n",
      "\n",
      "  • Updating rpds-py (0.10.2 -> 0.10.3)\n",
      "  • Updating six (1.16.0 /usr/lib/python3/dist-packages -> 1.16.0)\n",
      "  • Updating traitlets (5.7.1 -> 5.10.0)\n",
      "  • Installing arrow (1.2.3)\n",
      "  • Updating jsonschema (4.17.3 -> 4.19.0)\n",
      "  • Updating pyzmq (23.2.1 -> 25.1.1)\n",
      "  • Updating tornado (6.3.2 -> 6.3.3)\n",
      "  • Installing fqdn (1.5.1)\n",
      "  • Installing isoduration (20.11.0)\n",
      "  • Installing jsonpointer (2.4)\n",
      "  • Updating jupyter-client (6.1.12 -> 8.3.1)\n",
      "  • Installing rfc3339-validator (0.1.4)\n",
      "  • Installing rfc3986-validator (0.1.1)\n",
      "  • Installing uri-template (1.3.0)\n",
      "  • Installing asttokens (2.4.0)\n",
      "  • Updating beautifulsoup4 (4.11.2 -> 4.12.2)\n",
      "  • Installing executing (1.2.0)\n",
      "  • Installing pure-eval (0.2.2)\n",
      "  • Updating mistune (0.8.4 -> 3.0.1)\n",
      "  • Installing python-json-logger (2.0.7)\n",
      "  • Updating anyio (3.7.1 -> 4.0.0)\n",
      "  • Updating decorator (4.4.2 -> 5.1.1)\n",
      "  • Installing jedi (0.19.0)\n",
      "  • Installing jupyter-events (0.7.0)\n",
      "  • Installing jupyter-server-terminals (0.4.4)\n",
      "  • Updating nbconvert (6.5.4 -> 7.8.0)\n",
      "  • Installing overrides (7.4.0)\n",
      "  • Installing stack-data (0.6.2)\n",
      "  • Updating websocket-client (1.6.2 -> 1.6.3)\n",
      "  • Installing comm (0.1.4)\n",
      "  • Updating debugpy (1.6.6 -> 1.8.0)\n",
      "  • Updating ipython (7.34.0 -> 8.15.0)\n",
      "  • Installing json5 (0.9.14)\n",
      "  • Updating typing-extensions (4.5.0 -> 4.7.1)\n",
      "  • Updating jupyter-server (1.24.0 -> 2.7.3)\n",
      "  • Installing async-lru (2.0.4)\n",
      "  • Updating ipykernel (5.5.6 -> 6.25.2)\n",
      "  • Installing jupyter-lsp (2.2.0)\n",
      "  • Installing jupyterlab-server (2.25.0)\n",
      "  • Installing jupyterlab (4.0.6)\n",
      "  • Updating jupyterlab-widgets (3.0.8 -> 3.0.9)\n",
      "  • Installing qtpy (2.4.0)\n",
      "  • Updating widgetsnbextension (3.6.5 -> 4.0.9)\n",
      "  • Installing dawg-python (0.7.2)\n",
      "  • Updating filelock (3.12.2 -> 3.12.4)\n",
      "  • Installing docopt (0.6.2)\n",
      "  • Updating ipywidgets (7.7.1 -> 8.1.1)\n",
      "  • Updating jupyter-console (6.1.0 -> 6.6.3)\n",
      "  • Updating notebook (6.5.5 -> 7.0.3)\n",
      "  • Installing pymorphy2-dicts-ru (2.4.417127.4579844)\n",
      "  • Installing qtconsole (5.4.4)\n",
      "  • Updating regex (2023.6.3 -> 2023.8.8)\n",
      "  • Installing corus (0.10.0)\n",
      "  • Updating gdown (4.6.6 -> 4.7.1)\n",
      "  • Installing tweet-preprocessor (0.6.0)\n",
      "  • Installing pymorphy2 (0.9.1)\n",
      "  • Installing jupyter (1.0.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Loading and Preprocessing"
   ],
   "metadata": {
    "id": "HRWriMo2u41c"
   },
   "id": "HRWriMo2u41c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import deps"
   ],
   "metadata": {
    "collapsed": false,
    "id": "dca1d5278cf61bad"
   },
   "id": "dca1d5278cf61bad"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# This code includes software developed by the following open-source projects:\n",
    "# - NLTK (License: Apache License 2.0, Authors: Steven Bird, Edward Loper, Ewan Klein)\n",
    "# - preprocessor (License: MIT, Authors: Saurabh Mathur)\n",
    "# - Corus (License: MIT, Authors: Denis Emelin)\n",
    "# - Pymorphy2 (License: MIT, Authors: Mikhail Korobov)\n",
    "# - Jupyter Notebook (License: Modified BSD License, Authors: Project Jupyter)\n",
    "# For the full license information, please see the `licenses` directory.\n",
    "\n",
    "\n",
    "import nltk\n",
    "import preprocessor as p\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from corus import load_mokoron\n",
    "import pymorphy2"
   ],
   "metadata": {
    "id": "309681695a20c267"
   },
   "id": "309681695a20c267"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download the \"Mokoron Russian Twitter Corpus\" dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "dcae3b8b511680c9"
   },
   "id": "dcae3b8b511680c9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1H_xuXdB9_YkIZJMwr-UGY1cbMLJt4JgK\n",
      "From (redirected): https://drive.google.com/uc?id=1H_xuXdB9_YkIZJMwr-UGY1cbMLJt4JgK&confirm=t&uuid=1fdc78b8-9f59-47fb-8596-c09f3617108e\n",
      "To: /content/nlp-course-itmo/db.sql\n",
      "100% 3.28G/3.28G [00:34<00:00, 94.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown '1H_xuXdB9_YkIZJMwr-UGY1cbMLJt4JgK' -O 'db.sql'"
   ],
   "metadata": {
    "id": "bf3ca4807ca0c69d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "21f77c60-b623-4f14-d673-3f9ed68af61a"
   },
   "id": "bf3ca4807ca0c69d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "id": "a3d3487c8f0b0826"
   },
   "id": "a3d3487c8f0b0826"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "path = 'db.sql'\n",
    "records = load_mokoron(path)"
   ],
   "metadata": {
    "id": "d16650c7798ffb08"
   },
   "id": "d16650c7798ffb08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract text"
   ],
   "metadata": {
    "collapsed": false,
    "id": "338bc4077682982c"
   },
   "id": "338bc4077682982c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "N = 100000\n",
    "texts = [record.text for _, record in zip(range(N), records)]"
   ],
   "metadata": {
    "id": "520633f23c163506"
   },
   "id": "520633f23c163506"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load resources for nltk"
   ],
   "metadata": {
    "collapsed": false,
    "id": "559825525289bb68"
   },
   "id": "559825525289bb68"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "id": "b96d3d744e77e201",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6df12d1e-4b2f-40a1-a290-663ebd655eaf"
   },
   "id": "b96d3d744e77e201"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lowercase the text"
   ],
   "metadata": {
    "collapsed": false,
    "id": "a0e6457eaae071c6"
   },
   "id": "a0e6457eaae071c6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "texts = [text.lower() for text in texts]"
   ],
   "metadata": {
    "id": "f065ef7351b8c51a"
   },
   "id": "f065ef7351b8c51a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove @tags, links and \\\\n noise"
   ],
   "metadata": {
    "collapsed": false,
    "id": "1fee4bbeb39dafff"
   },
   "id": "1fee4bbeb39dafff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text before the cleanup"
   ],
   "metadata": {
    "id": "fMZtcU5UwyHk"
   },
   "id": "fMZtcU5UwyHk"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['пропавшая в хабаровске школьница почти сутки провела в яме у коллектор',\n",
       " 'лента, я сегодня полгода дирекшионеееер! с:\\\\nхотя все равно никто не поздравит лол',\n",
       " 'царствие божие внутрь вас есть.',\n",
       " 'rt @twitregion: ученые: кофе приносит намного больше вреда, чем пиво',\n",
       " 'http://t.co/zzzwylsmon справка по адаптации 5 классников']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "texts[:5]"
   ],
   "metadata": {
    "id": "1b0848ac274cbd9a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e8ff2eca-ccc7-4b25-ea90-d4ad98c6c4a9"
   },
   "id": "1b0848ac274cbd9a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION)\n",
    "texts = [p.clean(text.replace('\\\\n', ' ')) for text in texts]"
   ],
   "metadata": {
    "id": "22b148b94a915c9e"
   },
   "id": "22b148b94a915c9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text after"
   ],
   "metadata": {
    "id": "bZ8-nx1Iw8WB"
   },
   "id": "bZ8-nx1Iw8WB"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['пропавшая в хабаровске школьница почти сутки провела в яме у коллектор',\n",
       " 'лента, я сегодня полгода дирекшионеееер! с:хотя все равно никто не поздравит лол',\n",
       " 'царствие божие внутрь вас есть.',\n",
       " 'rt : ученые: кофе приносит намного больше вреда, чем пиво',\n",
       " 'справка по адаптации 5 классников']"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "texts[:5]"
   ],
   "metadata": {
    "id": "1b99866393dcdf6b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "085ee6fc-a9d5-485b-de60-e4e43d77660a"
   },
   "id": "1b99866393dcdf6b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenize the text"
   ],
   "metadata": {
    "collapsed": false,
    "id": "14b8fe3a45819177"
   },
   "id": "14b8fe3a45819177"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()\n",
    "tokenized_texts = [tknzr.tokenize(text) for text in texts]"
   ],
   "metadata": {
    "id": "defc5e516755b4a9"
   },
   "id": "defc5e516755b4a9"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['пропавшая',\n",
       "  'в',\n",
       "  'хабаровске',\n",
       "  'школьница',\n",
       "  'почти',\n",
       "  'сутки',\n",
       "  'провела',\n",
       "  'в',\n",
       "  'яме',\n",
       "  'у',\n",
       "  'коллектор'],\n",
       " ['лента',\n",
       "  ',',\n",
       "  'я',\n",
       "  'сегодня',\n",
       "  'полгода',\n",
       "  'дирекшионееер',\n",
       "  '!',\n",
       "  'с',\n",
       "  ':',\n",
       "  'хотя',\n",
       "  'все',\n",
       "  'равно',\n",
       "  'никто',\n",
       "  'не',\n",
       "  'поздравит',\n",
       "  'лол'],\n",
       " ['царствие', 'божие', 'внутрь', 'вас', 'есть', '.'],\n",
       " ['rt',\n",
       "  ':',\n",
       "  'ученые',\n",
       "  ':',\n",
       "  'кофе',\n",
       "  'приносит',\n",
       "  'намного',\n",
       "  'больше',\n",
       "  'вреда',\n",
       "  ',',\n",
       "  'чем',\n",
       "  'пиво'],\n",
       " ['справка', 'по', 'адаптации', '5', 'классников']]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "tokenized_texts[:5]"
   ],
   "metadata": {
    "id": "8b129b8dd276ddfd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b8f36c37-c04f-4c8f-cb70-1ae434b11769"
   },
   "id": "8b129b8dd276ddfd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove punctuation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "c2c481f332d4dc9b"
   },
   "id": "c2c481f332d4dc9b"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "exclude_punctuations = {',', '.', ';', ':', '\"', \"'\", \"{\", \"}\", \"[\", \"]\", \"*\", \"-\", \"—\", \"_\", \"/\", \"\\\\\", \"&\"}\n",
    "filtered_texts = [[token for token in text if token not in exclude_punctuations] for text in tokenized_texts]"
   ],
   "metadata": {
    "id": "f199f25bc15908bf"
   },
   "id": "f199f25bc15908bf"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['пропавшая',\n",
       "  'в',\n",
       "  'хабаровске',\n",
       "  'школьница',\n",
       "  'почти',\n",
       "  'сутки',\n",
       "  'провела',\n",
       "  'в',\n",
       "  'яме',\n",
       "  'у',\n",
       "  'коллектор'],\n",
       " ['лента',\n",
       "  'я',\n",
       "  'сегодня',\n",
       "  'полгода',\n",
       "  'дирекшионееер',\n",
       "  '!',\n",
       "  'с',\n",
       "  ':\\\\',\n",
       "  'nхотя',\n",
       "  'все',\n",
       "  'равно',\n",
       "  'никто',\n",
       "  'не',\n",
       "  'поздравит',\n",
       "  'лол'],\n",
       " ['царствие', 'божие', 'внутрь', 'вас', 'есть'],\n",
       " ['rt',\n",
       "  'ученые',\n",
       "  'кофе',\n",
       "  'приносит',\n",
       "  'намного',\n",
       "  'больше',\n",
       "  'вреда',\n",
       "  'чем',\n",
       "  'пиво'],\n",
       " ['справка', 'по', 'адаптации', '5', 'классников']]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "filtered_texts[:5]"
   ],
   "metadata": {
    "id": "d78b5eb243596762",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0ce930ab-625b-4926-f331-1ae8e516f724"
   },
   "id": "d78b5eb243596762"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove stop-words"
   ],
   "metadata": {
    "collapsed": false,
    "id": "9fdfe0295b9c53a4"
   },
   "id": "9fdfe0295b9c53a4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "filtered_texts = [[word for word in text if word not in russian_stopwords] for text in filtered_texts]"
   ],
   "metadata": {
    "id": "98fee96826ca0515"
   },
   "id": "98fee96826ca0515"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['пропавшая',\n",
       "  'хабаровске',\n",
       "  'школьница',\n",
       "  'сутки',\n",
       "  'провела',\n",
       "  'яме',\n",
       "  'коллектор'],\n",
       " ['лента',\n",
       "  'сегодня',\n",
       "  'полгода',\n",
       "  'дирекшионееер',\n",
       "  '!',\n",
       "  ':\\\\',\n",
       "  'nхотя',\n",
       "  'равно',\n",
       "  'никто',\n",
       "  'поздравит',\n",
       "  'лол'],\n",
       " ['царствие', 'божие', 'внутрь'],\n",
       " ['rt', 'ученые', 'кофе', 'приносит', 'намного', 'вреда', 'пиво'],\n",
       " ['справка', 'адаптации', '5', 'классников']]"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "filtered_texts[:5]"
   ],
   "metadata": {
    "id": "64100e0fc550c61a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ac32ef40-6442-45ca-a227-6ad782b3e616"
   },
   "id": "64100e0fc550c61a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lemmatize the text"
   ],
   "metadata": {
    "collapsed": false,
    "id": "c297810e18b31286"
   },
   "id": "c297810e18b31286"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "lemmatized_texts = [[morph.parse(word)[0].normal_form for word in text] for text in filtered_texts]"
   ],
   "metadata": {
    "id": "ffce6f1b1aa48ecf"
   },
   "id": "ffce6f1b1aa48ecf"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['пропасть',\n",
       "  'хабаровск',\n",
       "  'школьница',\n",
       "  'сутки',\n",
       "  'провести',\n",
       "  'яма',\n",
       "  'коллектор'],\n",
       " ['лента',\n",
       "  'сегодня',\n",
       "  'полгода',\n",
       "  'дирекшионееер',\n",
       "  '!',\n",
       "  ':\\\\',\n",
       "  'nхотеть',\n",
       "  'равно',\n",
       "  'никто',\n",
       "  'поздравить',\n",
       "  'лола'],\n",
       " ['царствие', 'божий', 'внутрь'],\n",
       " ['rt', 'учёный', 'кофе', 'приносить', 'намного', 'вред', 'пиво'],\n",
       " ['справка', 'адаптация', '5', 'классник']]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "lemmatized_texts[:5]"
   ],
   "metadata": {
    "id": "2c09a120be0e5015",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2ce383ef-4f0c-4724-dc1d-8ed9d0408023"
   },
   "id": "2c09a120be0e5015"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
